# %% [markdown]
# <h1><center>Zomato Mumbai Data Analysis Project</center></h1>

# %% [markdown]
# ![Zomato.png](https://upload.wikimedia.org/wikipedia/commons/8/8a/Zomato_Logo.png)

# %% [markdown]
# ##### This CSV dataset contains information pertaining to various Zomato restaurants in Mumbai, like restaurant names, cuisine, ratings, votes, location, etc.<br>
# ##### This dataset will help you with answering various questions, like which is the highest rated Seafood Restaurant, or which locality has the best Japanese restaurants, and so on.

# %% [markdown]
# ## 1. Importing the libraries

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:48.388777Z","iopub.execute_input":"2022-04-24T10:30:48.389135Z","iopub.status.idle":"2022-04-24T10:30:50.567358Z","shell.execute_reply.started":"2022-04-24T10:30:48.389038Z","shell.execute_reply":"2022-04-24T10:30:50.566533Z"}}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

# %% [markdown]
# ## 2. Importing the dataset

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:50.569115Z","iopub.execute_input":"2022-04-24T10:30:50.569436Z","iopub.status.idle":"2022-04-24T10:30:50.684146Z","shell.execute_reply.started":"2022-04-24T10:30:50.569393Z","shell.execute_reply":"2022-04-24T10:30:50.683531Z"}}
raw_df = pd.read_csv('../input/zomato-mumbai-dataset/Zomato_Mumbai_Dataset.csv',delimiter='|')

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:50.685358Z","iopub.execute_input":"2022-04-24T10:30:50.686079Z","iopub.status.idle":"2022-04-24T10:30:50.711597Z","shell.execute_reply.started":"2022-04-24T10:30:50.686044Z","shell.execute_reply":"2022-04-24T10:30:50.710516Z"}}
raw_df.head()

# %% [markdown]
# ## 3. Getting Basic Information about the Dataset

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:50.713289Z","iopub.execute_input":"2022-04-24T10:30:50.713534Z","iopub.status.idle":"2022-04-24T10:30:50.719018Z","shell.execute_reply.started":"2022-04-24T10:30:50.713503Z","shell.execute_reply":"2022-04-24T10:30:50.718398Z"}}
raw_df.shape

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:50.720433Z","iopub.execute_input":"2022-04-24T10:30:50.720908Z","iopub.status.idle":"2022-04-24T10:30:50.766818Z","shell.execute_reply.started":"2022-04-24T10:30:50.720788Z","shell.execute_reply":"2022-04-24T10:30:50.766267Z"}}
raw_df.info()

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:50.767885Z","iopub.execute_input":"2022-04-24T10:30:50.768518Z","iopub.status.idle":"2022-04-24T10:30:50.859599Z","shell.execute_reply.started":"2022-04-24T10:30:50.768484Z","shell.execute_reply":"2022-04-24T10:30:50.858682Z"}}
raw_df.describe()

# %% [markdown]
# ## 4. Cleaning the Dataset

# %% [markdown]
# ### a. Removing the redundunt rows of data

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:50.861115Z","iopub.execute_input":"2022-04-24T10:30:50.861622Z","iopub.status.idle":"2022-04-24T10:30:50.887215Z","shell.execute_reply.started":"2022-04-24T10:30:50.861577Z","shell.execute_reply":"2022-04-24T10:30:50.886502Z"}}
# Checking redundunt rows of data

wrong_data = raw_df['PAGE NO'] == 'PAGE NO'
raw_df[wrong_data]

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:50.888497Z","iopub.execute_input":"2022-04-24T10:30:50.888877Z","iopub.status.idle":"2022-04-24T10:30:50.898061Z","shell.execute_reply.started":"2022-04-24T10:30:50.888843Z","shell.execute_reply":"2022-04-24T10:30:50.897414Z"}}
## Performing Negation of the wrong dataset and then storing the correct data back in the raw_df DataFrame
## This permamnently remove the wrong data from the original dataframe

raw_df = raw_df[~wrong_data]

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:50.899271Z","iopub.execute_input":"2022-04-24T10:30:50.899652Z","iopub.status.idle":"2022-04-24T10:30:50.911130Z","shell.execute_reply.started":"2022-04-24T10:30:50.899620Z","shell.execute_reply":"2022-04-24T10:30:50.910389Z"}}
# Dropping columns which are not required for further analysis

raw_df.drop(['URL', 'PAGE NO', 'CITY'], axis = 1, inplace=True)

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:50.913924Z","iopub.execute_input":"2022-04-24T10:30:50.914279Z","iopub.status.idle":"2022-04-24T10:30:50.930564Z","shell.execute_reply.started":"2022-04-24T10:30:50.914250Z","shell.execute_reply":"2022-04-24T10:30:50.929925Z"}}
raw_df.head()

# %% [markdown]
# ### b. Removing the Null Records

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:50.931518Z","iopub.execute_input":"2022-04-24T10:30:50.932006Z","iopub.status.idle":"2022-04-24T10:30:50.953532Z","shell.execute_reply.started":"2022-04-24T10:30:50.931970Z","shell.execute_reply":"2022-04-24T10:30:50.952763Z"}}
# Checking for Null records

raw_df.isnull().sum()

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:50.954535Z","iopub.execute_input":"2022-04-24T10:30:50.955129Z","iopub.status.idle":"2022-04-24T10:30:50.973401Z","shell.execute_reply.started":"2022-04-24T10:30:50.955072Z","shell.execute_reply":"2022-04-24T10:30:50.972543Z"}}
# Checking for a null row

raw_df[raw_df['PRICE'].isnull()]

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:50.974570Z","iopub.execute_input":"2022-04-24T10:30:50.974879Z","iopub.status.idle":"2022-04-24T10:30:50.981272Z","shell.execute_reply.started":"2022-04-24T10:30:50.974845Z","shell.execute_reply":"2022-04-24T10:30:50.980384Z"}}
# Droping the above row from the dataset

raw_df = raw_df.drop(labels=15080, axis=0)

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:50.982542Z","iopub.execute_input":"2022-04-24T10:30:50.983341Z","iopub.status.idle":"2022-04-24T10:30:51.006484Z","shell.execute_reply.started":"2022-04-24T10:30:50.983295Z","shell.execute_reply":"2022-04-24T10:30:51.005864Z"}}
# Replacing the other null records with NA 

raw_df.fillna('NA', inplace=True)

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.007891Z","iopub.execute_input":"2022-04-24T10:30:51.008374Z","iopub.status.idle":"2022-04-24T10:30:51.038189Z","shell.execute_reply.started":"2022-04-24T10:30:51.008328Z","shell.execute_reply":"2022-04-24T10:30:51.037344Z"}}
# Confirming all the null records are correct 

raw_df.isnull().sum()

# %% [markdown]
# ### c. Converting the DataTypes of numerical columns to numeric dataype

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.039699Z","iopub.execute_input":"2022-04-24T10:30:51.040135Z","iopub.status.idle":"2022-04-24T10:30:51.051826Z","shell.execute_reply.started":"2022-04-24T10:30:51.040103Z","shell.execute_reply":"2022-04-24T10:30:51.050817Z"}}
# Checking for text values in the column before converting it to numeric datatype

raw_df['RATING'].value_counts()

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.053809Z","iopub.execute_input":"2022-04-24T10:30:51.054408Z","iopub.status.idle":"2022-04-24T10:30:51.067830Z","shell.execute_reply.started":"2022-04-24T10:30:51.054360Z","shell.execute_reply":"2022-04-24T10:30:51.067115Z"}}
# Replacing the text values with '0'

raw_df['RATING'].replace(to_replace=['-','NEW','Opening'], value='0', inplace=True)

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.069252Z","iopub.execute_input":"2022-04-24T10:30:51.070988Z","iopub.status.idle":"2022-04-24T10:30:51.080194Z","shell.execute_reply.started":"2022-04-24T10:30:51.070953Z","shell.execute_reply":"2022-04-24T10:30:51.079666Z"}}
# Checking for text values in the column before converting it to numeric datatype

raw_df['VOTES'].value_counts()

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.081217Z","iopub.execute_input":"2022-04-24T10:30:51.081976Z","iopub.status.idle":"2022-04-24T10:30:51.090655Z","shell.execute_reply.started":"2022-04-24T10:30:51.081940Z","shell.execute_reply":"2022-04-24T10:30:51.089931Z"}}
# Replacing the text values with '0'

raw_df['VOTES'].replace(to_replace=['-','NEW','Opening'], value='0', inplace=True)

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.091679Z","iopub.execute_input":"2022-04-24T10:30:51.092130Z","iopub.status.idle":"2022-04-24T10:30:51.107675Z","shell.execute_reply.started":"2022-04-24T10:30:51.092096Z","shell.execute_reply":"2022-04-24T10:30:51.106807Z"}}
# Changing Data Type of the numerical columns

raw_df['PRICE'] = raw_df['PRICE'].astype('int64')
raw_df['RATING'] = raw_df['RATING'].astype('float64')
raw_df['VOTES'] = raw_df['VOTES'].astype('int64')

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.108899Z","iopub.execute_input":"2022-04-24T10:30:51.109146Z","iopub.status.idle":"2022-04-24T10:30:51.138900Z","shell.execute_reply.started":"2022-04-24T10:30:51.109116Z","shell.execute_reply":"2022-04-24T10:30:51.137966Z"}}
raw_df.info()

# %% [markdown]
# ### d. Working with 'Timing' column

# %% [code] {"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.140126Z","iopub.execute_input":"2022-04-24T10:30:51.140498Z","iopub.status.idle":"2022-04-24T10:30:51.150414Z","shell.execute_reply.started":"2022-04-24T10:30:51.140435Z","shell.execute_reply":"2022-04-24T10:30:51.149731Z"}}
raw_df['TIMING'].value_counts()

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.151578Z","iopub.execute_input":"2022-04-24T10:30:51.151942Z","iopub.status.idle":"2022-04-24T10:30:51.312651Z","shell.execute_reply.started":"2022-04-24T10:30:51.151911Z","shell.execute_reply":"2022-04-24T10:30:51.311772Z"}}
# Splitting the column and storing it in temp_df dataframe 

temp_df = raw_df['TIMING'].str.split("(", n = 1, expand = True)
temp_df

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.313992Z","iopub.execute_input":"2022-04-24T10:30:51.314229Z","iopub.status.idle":"2022-04-24T10:30:51.332561Z","shell.execute_reply.started":"2022-04-24T10:30:51.314199Z","shell.execute_reply":"2022-04-24T10:30:51.331714Z"}}
# Assigning the columns back to the raw_df dataframe

raw_df['TIMING'] = temp_df[0]
raw_df['DAYS_OPEN'] = temp_df[1]
raw_df.head()

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.333772Z","iopub.execute_input":"2022-04-24T10:30:51.334607Z","iopub.status.idle":"2022-04-24T10:30:51.361993Z","shell.execute_reply.started":"2022-04-24T10:30:51.334567Z","shell.execute_reply":"2022-04-24T10:30:51.361228Z"}}
# Removing the bracket character from Days column

raw_df['DAYS_OPEN'] = raw_df['DAYS_OPEN'].str.replace(')','',regex=True)
raw_df.head()

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.363157Z","iopub.execute_input":"2022-04-24T10:30:51.363414Z","iopub.status.idle":"2022-04-24T10:30:51.385393Z","shell.execute_reply.started":"2022-04-24T10:30:51.363384Z","shell.execute_reply":"2022-04-24T10:30:51.384542Z"}}
# Checking for Null records in DAYS_OPEN column

raw_df.isnull().sum()

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.386562Z","iopub.execute_input":"2022-04-24T10:30:51.386766Z","iopub.status.idle":"2022-04-24T10:30:51.405321Z","shell.execute_reply.started":"2022-04-24T10:30:51.386739Z","shell.execute_reply":"2022-04-24T10:30:51.404709Z"}}
# Replacing the Null values with 'NA'

raw_df.fillna('NA', inplace=True)

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.410169Z","iopub.execute_input":"2022-04-24T10:30:51.410610Z","iopub.status.idle":"2022-04-24T10:30:51.436106Z","shell.execute_reply.started":"2022-04-24T10:30:51.410559Z","shell.execute_reply":"2022-04-24T10:30:51.435231Z"}}
# Checking info of all the columns

raw_df.info()

# %% [markdown]
# ### e. Removing the restaurant records whose Rating or Votes is 0

# %% [code] {"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.438710Z","iopub.execute_input":"2022-04-24T10:30:51.439229Z","iopub.status.idle":"2022-04-24T10:30:51.469480Z","shell.execute_reply.started":"2022-04-24T10:30:51.439192Z","shell.execute_reply":"2022-04-24T10:30:51.468547Z"}}
# Finding those restaurant whose has 0 Rating or Votes

useless_data = (raw_df['RATING'] == 0.0) | (raw_df['VOTES'] == 0)
raw_df[useless_data]

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.470678Z","iopub.execute_input":"2022-04-24T10:30:51.470934Z","iopub.status.idle":"2022-04-24T10:30:51.477278Z","shell.execute_reply.started":"2022-04-24T10:30:51.470906Z","shell.execute_reply":"2022-04-24T10:30:51.476429Z"}}
## Performing Negation of the useless dataset and then storing the correct data back in the raw_df DataFrame
## This permamnently remove the wrong data from the original dataframe

raw_df = raw_df[~useless_data]

# %% [markdown]
# ### f. Working on 'RATING_TYPE' Column

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.478250Z","iopub.execute_input":"2022-04-24T10:30:51.478996Z","iopub.status.idle":"2022-04-24T10:30:51.495056Z","shell.execute_reply.started":"2022-04-24T10:30:51.478962Z","shell.execute_reply":"2022-04-24T10:30:51.493971Z"}}
# Checking the unique values in the column

raw_df['RATING_TYPE'].value_counts()

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.496552Z","iopub.execute_input":"2022-04-24T10:30:51.497164Z","iopub.status.idle":"2022-04-24T10:30:51.531285Z","shell.execute_reply.started":"2022-04-24T10:30:51.497115Z","shell.execute_reply":"2022-04-24T10:30:51.530549Z"}}
# Translating the texts into proper English text

raw_df['RATING_TYPE'].replace(to_replace='Excelente' , value='Excellent', inplace=True)
raw_df['RATING_TYPE'].replace(to_replace=['Veľmi dobré','Bardzo dobrze','Muy Bueno','Velmi dobré'] , value='Very Good', inplace=True)
raw_df['RATING_TYPE'].replace(to_replace=['Skvělá volba','Dobrze','Bueno','Buono','Dobré','Bom','Skvělé'] , value='Good', inplace=True)
raw_df['RATING_TYPE'].replace(to_replace=['Priemer','Média','Çok iyi'] , value='Average', inplace=True)
raw_df['RATING_TYPE'].replace(to_replace=['Průměr','Promedio','Ortalama','Muito Bom','İyi'] , value='Poor', inplace=True)
raw_df['RATING_TYPE'].replace(to_replace=['Baik','Biasa','Media','Sangat Baik'] , value='Very Poor', inplace=True)

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.532679Z","iopub.execute_input":"2022-04-24T10:30:51.532985Z","iopub.status.idle":"2022-04-24T10:30:51.542026Z","shell.execute_reply.started":"2022-04-24T10:30:51.532941Z","shell.execute_reply":"2022-04-24T10:30:51.541232Z"}}
# Checking all the values correctly mapped

raw_df['RATING_TYPE'].value_counts()

# %% [markdown]
# ### g. Working on 'REGION' Column

# %% [code] {"tags":[],"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.543492Z","iopub.execute_input":"2022-04-24T10:30:51.544378Z","iopub.status.idle":"2022-04-24T10:30:51.558993Z","shell.execute_reply.started":"2022-04-24T10:30:51.544334Z","shell.execute_reply":"2022-04-24T10:30:51.557889Z"}}
raw_df['REGION'].value_counts()

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.560065Z","iopub.execute_input":"2022-04-24T10:30:51.560328Z","iopub.status.idle":"2022-04-24T10:30:51.585722Z","shell.execute_reply.started":"2022-04-24T10:30:51.560296Z","shell.execute_reply":"2022-04-24T10:30:51.585024Z"}}
# Removing the irrelevant text from the Region column

raw_df['REGION'] = raw_df['REGION'].str.replace('[a-zA-Z].+-- ','',regex=True)

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.586947Z","iopub.execute_input":"2022-04-24T10:30:51.587351Z","iopub.status.idle":"2022-04-24T10:30:51.606278Z","shell.execute_reply.started":"2022-04-24T10:30:51.587319Z","shell.execute_reply":"2022-04-24T10:30:51.605672Z"}}
# Removing the West & East from the Region column

raw_df['REGION'] = raw_df['REGION'].str.replace(' West| west| East| east','',regex=True)

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.607565Z","iopub.execute_input":"2022-04-24T10:30:51.607882Z","iopub.status.idle":"2022-04-24T10:30:51.618125Z","shell.execute_reply.started":"2022-04-24T10:30:51.607839Z","shell.execute_reply":"2022-04-24T10:30:51.617420Z"}}
raw_df['REGION'].value_counts()

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.619279Z","iopub.execute_input":"2022-04-24T10:30:51.619992Z","iopub.status.idle":"2022-04-24T10:30:51.756116Z","shell.execute_reply.started":"2022-04-24T10:30:51.619916Z","shell.execute_reply":"2022-04-24T10:30:51.755353Z"}}
# Replacing Small regions with Known region name

raw_df['REGION'] = raw_df['REGION'].str.replace('4 Bungalows|7 Andheri|Azad Nagar|Near Andheri Station|Veera Desai Area|Mahakali','Andheri',regex=True)
raw_df['REGION'] = raw_df['REGION'].str.replace('Bandra Kurla Complex','Bandra',regex=True)
raw_df['REGION'] = raw_df['REGION'].str.replace('CBD-Belapur','CBD Belapur',regex=True)
raw_df['REGION'] = raw_df['REGION'].str.replace('Girgaon Chowpatty','Chowpatty',regex=True)
raw_df['REGION'] = raw_df['REGION'].str.replace('Dadar Shivaji Park','Dadar',regex=True)
raw_df['REGION'] = raw_df['REGION'].str.replace('Flea Bazaar Café|Kamala Mills Compound','Lower Parel',regex=True)
raw_df['REGION'] = raw_df['REGION'].str.replace('Runwal Green','Mulund',regex=True)
raw_df['REGION'] = raw_df['REGION'].str.replace('Mumbai CST Area','Mumbai Central',regex=True)
raw_df['REGION'] = raw_df['REGION'].str.replace('Kopar Khairane|Seawoods|Turbhe|Ulwe','Navi Mumbai',regex=True)
raw_df['REGION'] = raw_df['REGION'].str.replace('New Panvel|Old Panvel','Panvel',regex=True)
raw_df['REGION'] = raw_df['REGION'].str.replace('Kamothe','Sion',regex=True)
raw_df['REGION'] = raw_df['REGION'].str.replace('Ghodbunder Road|Majiwada','Thane',regex=True)

# %% [markdown]
# ### h. Removing Duplicate records

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.757314Z","iopub.execute_input":"2022-04-24T10:30:51.757729Z","iopub.status.idle":"2022-04-24T10:30:51.793660Z","shell.execute_reply.started":"2022-04-24T10:30:51.757693Z","shell.execute_reply":"2022-04-24T10:30:51.793084Z"}}
# Finding all the duplicate rows

raw_df[raw_df.duplicated()]

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.794613Z","iopub.execute_input":"2022-04-24T10:30:51.795226Z","iopub.status.idle":"2022-04-24T10:30:51.813100Z","shell.execute_reply.started":"2022-04-24T10:30:51.795189Z","shell.execute_reply":"2022-04-24T10:30:51.812512Z"}}
# Dropping all the duplicate rows

raw_df = raw_df.drop_duplicates()

# %% [markdown]
# ## 4. Copying the cleaned data into a new DataFrame

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.814202Z","iopub.execute_input":"2022-04-24T10:30:51.814571Z","iopub.status.idle":"2022-04-24T10:30:51.820492Z","shell.execute_reply.started":"2022-04-24T10:30:51.814529Z","shell.execute_reply":"2022-04-24T10:30:51.818252Z"}}
zomato_df = raw_df.copy()

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.821849Z","iopub.execute_input":"2022-04-24T10:30:51.822438Z","iopub.status.idle":"2022-04-24T10:30:51.847249Z","shell.execute_reply.started":"2022-04-24T10:30:51.822386Z","shell.execute_reply":"2022-04-24T10:30:51.846490Z"}}
zomato_df.head()

# %% [markdown]
# ## 5. Performing Exploratory Data Analysis

# %% [markdown]
# #### Q1) How many restaurants are in Mumbai for each type of cuisine?

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:51.848443Z","iopub.execute_input":"2022-04-24T10:30:51.849233Z","iopub.status.idle":"2022-04-24T10:30:53.009594Z","shell.execute_reply.started":"2022-04-24T10:30:51.849197Z","shell.execute_reply":"2022-04-24T10:30:53.008939Z"}}
fig = px.histogram(zomato_df, x='CUSINE TYPE', color='CUSINE TYPE', 
             title= 'No. of Restaurants by Cuisine Type', 
             labels={'CUSINE TYPE':'Cuisine Type'})

fig.show()

# %% [markdown]
# #### Q2) What are the percentage of restaurants by Rating Type in Mumbai?

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.010764Z","iopub.execute_input":"2022-04-24T10:30:53.011317Z","iopub.status.idle":"2022-04-24T10:30:53.024972Z","shell.execute_reply.started":"2022-04-24T10:30:53.011284Z","shell.execute_reply":"2022-04-24T10:30:53.024221Z"}}
rating_type_df = zomato_df['RATING_TYPE'].value_counts().reset_index()
rating_type_df.rename(columns={'index':'RATING TYPE', 'RATING_TYPE':'COUNT OF RESTAURANTS'}, inplace=True)
rating_type_df

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.026331Z","iopub.execute_input":"2022-04-24T10:30:53.026662Z","iopub.status.idle":"2022-04-24T10:30:53.101695Z","shell.execute_reply.started":"2022-04-24T10:30:53.026631Z","shell.execute_reply":"2022-04-24T10:30:53.100741Z"}}
fig = px.pie(rating_type_df, names='RATING TYPE', values='COUNT OF RESTAURANTS', color='RATING TYPE', 
       title='Percentage of Restaurants by Rating Type').update_traces(textposition='inside', textinfo='percent+label')

fig.show()

# %% [markdown]
# #### Q3) Which are the Top 10 highest rated Seafood Restaurant in Mumbai?

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.103007Z","iopub.execute_input":"2022-04-24T10:30:53.103553Z","iopub.status.idle":"2022-04-24T10:30:53.130795Z","shell.execute_reply.started":"2022-04-24T10:30:53.103520Z","shell.execute_reply":"2022-04-24T10:30:53.129926Z"}}
seafood_df = zomato_df[zomato_df['CUSINE_CATEGORY'].str.contains('Seafood')]
seafood_df.sort_values(by='RATING',ascending=False).head(10)

# %% [markdown]
# #### Q4) Which is the best Food Truck in Mumbai?

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.132015Z","iopub.execute_input":"2022-04-24T10:30:53.132250Z","iopub.status.idle":"2022-04-24T10:30:53.149848Z","shell.execute_reply.started":"2022-04-24T10:30:53.132220Z","shell.execute_reply":"2022-04-24T10:30:53.149012Z"}}
foodtruck_df = zomato_df[zomato_df['CUSINE TYPE'] == 'Food Truck']
foodtruck_df.sort_values(by='RATING',ascending=False).head(2)

# %% [markdown]
# #### Q5) Which places have the highest rated restaurant for each Cuisine Type in Mumbai?

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.151261Z","iopub.execute_input":"2022-04-24T10:30:53.151518Z","iopub.status.idle":"2022-04-24T10:30:53.175335Z","shell.execute_reply.started":"2022-04-24T10:30:53.151461Z","shell.execute_reply":"2022-04-24T10:30:53.174514Z"}}
# Assuming restaurants having rating above 4.5

highest_rated_df = zomato_df[zomato_df['RATING'] >= 4.5]
highest_rated_df

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.176673Z","iopub.execute_input":"2022-04-24T10:30:53.176908Z","iopub.status.idle":"2022-04-24T10:30:53.275753Z","shell.execute_reply.started":"2022-04-24T10:30:53.176878Z","shell.execute_reply":"2022-04-24T10:30:53.274963Z"}}
fig = px.histogram(highest_rated_df, x='REGION', color='CUSINE TYPE', 
             title= 'No. of Best Restaurant for each Cuisine Type by Places').update_xaxes(categoryorder="total descending")

fig.show()

# %% [markdown]
# #### Q6) What is the Avg Price Distibution of highest rated restaurant for each Cuisine Type in Mumbai?

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.276961Z","iopub.execute_input":"2022-04-24T10:30:53.277192Z","iopub.status.idle":"2022-04-24T10:30:53.295372Z","shell.execute_reply.started":"2022-04-24T10:30:53.277162Z","shell.execute_reply":"2022-04-24T10:30:53.294694Z"}}
highest_rated_price_df = highest_rated_df.groupby(by=['REGION', 'CUSINE TYPE'])['PRICE'].mean().reset_index()
highest_rated_price_df.head()

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.296603Z","iopub.execute_input":"2022-04-24T10:30:53.297458Z","iopub.status.idle":"2022-04-24T10:30:53.411036Z","shell.execute_reply.started":"2022-04-24T10:30:53.297412Z","shell.execute_reply":"2022-04-24T10:30:53.410251Z"}}
fig = px.scatter(highest_rated_price_df, x="REGION", y="PRICE", color="CUSINE TYPE", symbol="CUSINE TYPE", 
           title=' Avg Price Distibution of High rated restaurant for each Cuisine Type').update_traces(marker_size=10)

fig.show()

# %% [markdown]
# #### Q7) Which areas have a large number of Chinese Restaurant Market?

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.412288Z","iopub.execute_input":"2022-04-24T10:30:53.413204Z","iopub.status.idle":"2022-04-24T10:30:53.444917Z","shell.execute_reply.started":"2022-04-24T10:30:53.413155Z","shell.execute_reply":"2022-04-24T10:30:53.444075Z"}}
chinese_df = zomato_df[zomato_df['CUSINE_CATEGORY'].str.contains('Chinese')]
chinese_df

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.446386Z","iopub.execute_input":"2022-04-24T10:30:53.447159Z","iopub.status.idle":"2022-04-24T10:30:53.466699Z","shell.execute_reply.started":"2022-04-24T10:30:53.447113Z","shell.execute_reply":"2022-04-24T10:30:53.465844Z"}}
chinese_rest_df = chinese_df.groupby(by='REGION').agg({'NAME' : 'count', 'PRICE' : 'mean'}).rename(columns= {'NAME' : 'COUNT OF RESTAURANTS'}).reset_index()
chinese_rest_df = chinese_rest_df.sort_values('COUNT OF RESTAURANTS', ascending=False).head(25)
chinese_rest_df.head()

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.468045Z","iopub.execute_input":"2022-04-24T10:30:53.468596Z","iopub.status.idle":"2022-04-24T10:30:53.560660Z","shell.execute_reply.started":"2022-04-24T10:30:53.468550Z","shell.execute_reply":"2022-04-24T10:30:53.560014Z"}}
fig = px.bar(chinese_rest_df, x='REGION', y='COUNT OF RESTAURANTS', color='PRICE', title= 'No. of Chinese Restaurant by Places')

fig.show()

# %% [markdown]
# #### Q8) Is there a relation between Price and Rating by each Cuisine Type?

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.561610Z","iopub.execute_input":"2022-04-24T10:30:53.562139Z","iopub.status.idle":"2022-04-24T10:30:53.581771Z","shell.execute_reply.started":"2022-04-24T10:30:53.562102Z","shell.execute_reply":"2022-04-24T10:30:53.581129Z"}}
price_rating_df = zomato_df.groupby(['CUSINE TYPE', 'RATING'])['PRICE'].mean().reset_index()
price_rating_df

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.582806Z","iopub.execute_input":"2022-04-24T10:30:53.583126Z","iopub.status.idle":"2022-04-24T10:30:53.742862Z","shell.execute_reply.started":"2022-04-24T10:30:53.583097Z","shell.execute_reply":"2022-04-24T10:30:53.742076Z"}}
fig = px.line(price_rating_df, y="PRICE", x="RATING",color='CUSINE TYPE')

fig.show()

# %% [markdown]
# #### Q9) Is there a relation between Region and Price?

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.744243Z","iopub.execute_input":"2022-04-24T10:30:53.745171Z","iopub.status.idle":"2022-04-24T10:30:53.761737Z","shell.execute_reply.started":"2022-04-24T10:30:53.745122Z","shell.execute_reply":"2022-04-24T10:30:53.760917Z"}}
region_price_df = zomato_df.groupby(['REGION'])['PRICE'].mean().reset_index()
region_price_df

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.763015Z","iopub.execute_input":"2022-04-24T10:30:53.763367Z","iopub.status.idle":"2022-04-24T10:30:53.825824Z","shell.execute_reply.started":"2022-04-24T10:30:53.763300Z","shell.execute_reply":"2022-04-24T10:30:53.824958Z"}}
fig = px.scatter(region_price_df, x="REGION", y="PRICE").update_traces(marker_size=8)

fig.show()

# %% [markdown]
# #### Q10) Find the list of Affordable Restaurants?

# %% [markdown]
# ##### The criteria for Affordable Restaurants would be:-
# 
# 1) Low Price
# 2) High Rated

# %% [markdown]
# First step will be to find the restaurants with average cost 1/4th the average cost of most expensive restaurant in our dataframe.
# 
# Let me explain:-The most expensive restaurant has an average meal cost= 6000. We'll try to stay economical and only pick the restaurants that are 1/4th of 6000.

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.827113Z","iopub.execute_input":"2022-04-24T10:30:53.827355Z","iopub.status.idle":"2022-04-24T10:30:53.833187Z","shell.execute_reply.started":"2022-04-24T10:30:53.827325Z","shell.execute_reply":"2022-04-24T10:30:53.832598Z"}}
max_price = zomato_df['PRICE'].max()
one_fourth_price = max_price/4
one_fourth_price

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.834142Z","iopub.execute_input":"2022-04-24T10:30:53.834843Z","iopub.status.idle":"2022-04-24T10:30:53.862054Z","shell.execute_reply.started":"2022-04-24T10:30:53.834799Z","shell.execute_reply":"2022-04-24T10:30:53.861181Z"}}
# Finding list of restaurants that have price less than and equal to 1/4th of the max price i.e Finding Cheap Restaurants

aff_rest_df = zomato_df[['NAME', 'PRICE', 'CUSINE_CATEGORY', 'REGION', 'CUSINE TYPE']]
aff_rest_df = aff_rest_df[aff_rest_df['PRICE'] <= 1250]
aff_rest_df.sort_values(by='PRICE', inplace=True)
aff_rest_df

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.863211Z","iopub.execute_input":"2022-04-24T10:30:53.865210Z","iopub.status.idle":"2022-04-24T10:30:53.886630Z","shell.execute_reply.started":"2022-04-24T10:30:53.865173Z","shell.execute_reply":"2022-04-24T10:30:53.885851Z"}}
# Finding the highest rated list of restaurants

highrate_rest_df = zomato_df[['NAME', 'PRICE', 'CUSINE_CATEGORY', 'REGION', 'CUSINE TYPE','RATING']]
highrate_rest_df = highrate_rest_df[highrate_rest_df['RATING'] >= 4.5]
highrate_rest_df.sort_values(by='PRICE', inplace=True)
highrate_rest_df

# %% [markdown]
# Now, we'll merge the <b>aff_rest_df</b> with <b>highrate_rest_df</b> to obtain the intersection i.e the list of Affordable Restaurants !!

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.887806Z","iopub.execute_input":"2022-04-24T10:30:53.888129Z","iopub.status.idle":"2022-04-24T10:30:53.907847Z","shell.execute_reply.started":"2022-04-24T10:30:53.888094Z","shell.execute_reply":"2022-04-24T10:30:53.907025Z"}}
highrate_aff_df = pd.merge(aff_rest_df, highrate_rest_df, how='inner', on=['NAME', 'REGION'])
highrate_aff_df = highrate_aff_df[['NAME', 'PRICE_x', 'CUSINE_CATEGORY_x', 'REGION', 'CUSINE TYPE_x']]
highrate_aff_df.rename(columns={'NAME':'NAME', 'PRICE_x':'PRICE', 'CUSINE_CATEGORY_x':'CUSINE_CATEGORY', 
                                'REGION':'REGION', 'CUSINE TYPE_x':'CUSINE TYPE'},inplace=True)

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.909046Z","iopub.execute_input":"2022-04-24T10:30:53.909365Z","iopub.status.idle":"2022-04-24T10:30:53.925518Z","shell.execute_reply.started":"2022-04-24T10:30:53.909328Z","shell.execute_reply":"2022-04-24T10:30:53.924836Z"}}
# Affordable Restaurants with low price and high rating 

highrate_aff_df

# %% [markdown]
# #### Q10) Find the list of most Reliable Restaurants?

# %% [markdown]
# ##### The criteria for most Reliable Restaurants would be:-
# 
# 1) Low Price
# 2) High Rated
# 3) Large No. of Votes

# %% [markdown]
# First step will be to find the restaurants with Votes greater than Mean of Votes

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.926656Z","iopub.execute_input":"2022-04-24T10:30:53.927405Z","iopub.status.idle":"2022-04-24T10:30:53.939200Z","shell.execute_reply.started":"2022-04-24T10:30:53.927369Z","shell.execute_reply":"2022-04-24T10:30:53.938296Z"}}
mean_votes = zomato_df['VOTES'].mean()
mean_votes

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.940344Z","iopub.execute_input":"2022-04-24T10:30:53.940582Z","iopub.status.idle":"2022-04-24T10:30:53.966770Z","shell.execute_reply.started":"2022-04-24T10:30:53.940543Z","shell.execute_reply":"2022-04-24T10:30:53.966056Z"}}
# Finding list of restaurants that have Votes greater than and equal to  Mean of Vote

mean_rest_df = zomato_df[['NAME', 'PRICE', 'CUSINE_CATEGORY', 'REGION', 'CUSINE TYPE', 'VOTES']]
mean_rest_df = mean_rest_df[mean_rest_df['VOTES'] > 177]
mean_rest_df.sort_values(by='VOTES', inplace=True)
mean_rest_df

# %% [markdown]
# ### These are the most reliable, highest rated and affordable restaurants:-
# 
# We obtain this dataframe by simply taking the intersection of highrate_aff_df & mean_rest_df
# 
# This dataframe obtained below shows the restaurants whose:
# 
# * Cost is below <b>1250</b>
# * Rating is above <b>4.5</b>
# * Votes are above <b>177</b>

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.970253Z","iopub.execute_input":"2022-04-24T10:30:53.970553Z","iopub.status.idle":"2022-04-24T10:30:53.984275Z","shell.execute_reply.started":"2022-04-24T10:30:53.970521Z","shell.execute_reply":"2022-04-24T10:30:53.983442Z"}}
reliable_rest_df = pd.merge(mean_rest_df, highrate_aff_df, how='inner', on=['NAME', 'REGION'])
reliable_rest_df = reliable_rest_df[['NAME', 'PRICE_x', 'CUSINE_CATEGORY_x', 'REGION', 'CUSINE TYPE_x']]
reliable_rest_df.rename(columns={'NAME':'NAME', 'PRICE_x':'PRICE', 'CUSINE_CATEGORY_x':'CUSINE_CATEGORY', 
                                'REGION':'REGION', 'CUSINE TYPE_x':'CUSINE TYPE'},inplace=True)

# %% [code] {"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-04-24T10:30:53.985353Z","iopub.execute_input":"2022-04-24T10:30:53.985680Z","iopub.status.idle":"2022-04-24T10:30:54.010454Z","shell.execute_reply.started":"2022-04-24T10:30:53.985637Z","shell.execute_reply":"2022-04-24T10:30:54.009625Z"}}
reliable_rest_df
